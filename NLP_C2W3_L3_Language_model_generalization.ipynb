{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_C2W3_L3_Language model generalization.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPZAxx3jVb7lYMUJpVhbfkP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Loga19818eeanvesh/Natural_Language_Processing-Assignments/blob/main/NLP_C2W3_L3_Language_model_generalization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaJPqKlseOp7",
        "outputId": "33174e2f-58c4-4d03-e533-cd9133c6b033"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the new vocabulary containing 3 most frequent words: ['happy', 'because', 'learning']\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# build the vocabulary from M most frequent words\n",
        "# use Counter object from the collections library to find M most common words\n",
        "from collections import Counter\n",
        "\n",
        "# the target size of the vocabulary\n",
        "M = 3\n",
        "\n",
        "# pre-calculated word counts\n",
        "# Counter could be used to build this dictionary from the source corpus\n",
        "word_counts = {'happy': 5, 'because': 3, 'i': 2, 'am': 2, 'learning': 3, '.': 1}\n",
        "\n",
        "vocabulary = Counter(word_counts).most_common(M)\n",
        "\n",
        "# remove the frequencies and leave just the words\n",
        "vocabulary = [w[0] for w in vocabulary]\n",
        "\n",
        "print(f\"the new vocabulary containing {M} most frequent words: {vocabulary}\\n\") "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test if words in the input sentences are in the vocabulary, if OOV, print <UNK>\n",
        "sentence = ['am', 'i', 'learning']\n",
        "output_sentence = []\n",
        "print(f\"input sentence: {sentence}\")\n",
        "\n",
        "for w in sentence:\n",
        "    # test if word w is in vocabulary\n",
        "    if w in vocabulary:\n",
        "        output_sentence.append(w)\n",
        "    else:\n",
        "        output_sentence.append('<UNK>')\n",
        "        \n",
        "print(f\"output sentence: {output_sentence}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YPd6N-GfQYR",
        "outputId": "ee6fc2f4-55fa-42ca-af04-8f374eebba53"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input sentence: ['am', 'i', 'learning']\n",
            "output sentence: ['<UNK>', '<UNK>', 'learning']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# iterate through all word counts and print words with given frequency f\n",
        "f = 3\n",
        "\n",
        "word_counts = {'happy': 5, 'because': 3, 'i': 2, 'am': 2, 'learning':3, '.': 1}\n",
        "\n",
        "for word, freq in word_counts.items():\n",
        "    if freq == f:\n",
        "        print(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7kVz3KlfZaW",
        "outputId": "15578c14-7241-40bc-c15a-b12cd07534ea"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "because\n",
            "learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# many <unk> low perplexity \n",
        "training_set = ['i', 'am', 'happy', 'because','i', 'am', 'learning', '.']\n",
        "training_set_unk = ['i', 'am', '<UNK>', '<UNK>','i', 'am', '<UNK>', '<UNK>']\n",
        "\n",
        "test_set = ['i', 'am', 'learning']\n",
        "test_set_unk = ['i', 'am', '<UNK>']\n",
        "\n",
        "M = len(test_set)\n",
        "probability = 1\n",
        "probability_unk = 1\n",
        "\n",
        "# pre-calculated probabilities\n",
        "bigram_probabilities = {('i', 'am'): 1.0, ('am', 'happy'): 0.5, ('happy', 'because'): 1.0, ('because', 'i'): 1.0, ('am', 'learning'): 0.5, ('learning', '.'): 1.0}\n",
        "bigram_probabilities_unk = {('i', 'am'): 1.0, ('am', '<UNK>'): 1.0, ('<UNK>', '<UNK>'): 0.5, ('<UNK>', 'i'): 0.25}\n",
        "\n",
        "# got through the test set and calculate its bigram probability\n",
        "for i in range(len(test_set) - 2 + 1):\n",
        "    bigram = tuple(test_set[i: i + 2])\n",
        "    probability = probability * bigram_probabilities[bigram]\n",
        "        \n",
        "    bigram_unk = tuple(test_set_unk[i: i + 2])\n",
        "    probability_unk = probability_unk * bigram_probabilities_unk[bigram_unk]\n",
        "\n",
        "# calculate perplexity for both original test set and test set with <UNK>\n",
        "perplexity = probability ** -1 / M\n",
        "perplexity_unk = probability_unk ** -1 / M\n",
        "\n",
        "print(f\"perplexity for the training set: {perplexity}\")\n",
        "print(f\"perplexity for the training set with <UNK>: {perplexity_unk}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "059AuJlXf0hz",
        "outputId": "f37083b6-172d-4fec-818a-07435f359e15"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "perplexity for the training set: 0.6666666666666666\n",
            "perplexity for the training set with <UNK>: 0.3333333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def add_k_smooting_probability(k, vocabulary_size, n_gram_count, n_gram_prefix_count):\n",
        "    numerator = n_gram_count + k\n",
        "    denominator = n_gram_prefix_count + k * vocabulary_size\n",
        "    return numerator / denominator\n",
        "\n",
        "trigram_probabilities = {('i', 'am', 'happy') : 2}\n",
        "bigram_probabilities = {( 'am', 'happy') : 10}\n",
        "vocabulary_size = 5\n",
        "k = 1\n",
        "\n",
        "probability_known_trigram = add_k_smooting_probability(k, vocabulary_size, trigram_probabilities[('i', 'am', 'happy')], \n",
        "                           bigram_probabilities[( 'am', 'happy')])\n",
        "\n",
        "probability_unknown_trigram = add_k_smooting_probability(k, vocabulary_size, 0, 0)\n",
        "\n",
        "print(f\"probability_known_trigram: {probability_known_trigram}\")\n",
        "print(f\"probability_unknown_trigram: {probability_unknown_trigram}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbb3W5gAgqQT",
        "outputId": "2882eef3-1b4d-45cc-cbea-790625e43236"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probability_known_trigram: 0.2\n",
            "probability_unknown_trigram: 0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pre-calculated probabilities of all types of n-grams\n",
        "trigram_probabilities = {('i', 'am', 'happy'): 0}\n",
        "bigram_probabilities = {( 'am', 'happy'): 0.3}\n",
        "unigram_probabilities = {'happy': 0.4}\n",
        "\n",
        "# this is the input trigram we need to estimate\n",
        "trigram = ('are', 'you', 'happy')\n",
        "\n",
        "# find the last bigram and unigram of the input\n",
        "bigram = trigram[1: 3]\n",
        "unigram = trigram[2]\n",
        "print(f\"besides the trigram {trigram} we also use bigram {bigram} and unigram ({unigram})\\n\")\n",
        "\n",
        "# 0.4 is used as an example, experimentally found for web-scale corpuses when using the \"stupid\" back-off\n",
        "lambda_factor = 0.4\n",
        "probability_hat_trigram = 0\n",
        "\n",
        "# search for first non-zero probability starting with trigram\n",
        "# to generalize this for any order of n-gram hierarchy, \n",
        "# you could loop through the probability dictionaries instead of if/else cascade\n",
        "if trigram not in trigram_probabilities or trigram_probabilities[trigram] == 0:\n",
        "    print(f\"probability for trigram {trigram} not found\")\n",
        "    \n",
        "    if bigram not in bigram_probabilities or bigram_probabilities[bigram] == 0:\n",
        "        print(f\"probability for bigram {bigram} not found\")\n",
        "        \n",
        "        if unigram in unigram_probabilities:\n",
        "            print(f\"probability for unigram {unigram} found\\n\")\n",
        "            probability_hat_trigram = lambda_factor * lambda_factor * unigram_probabilities[unigram]\n",
        "        else:\n",
        "            probability_hat_trigram = 0\n",
        "    else:\n",
        "        probability_hat_trigram = lambda_factor * bigram_probabilities[bigram]\n",
        "else:\n",
        "    probability_hat_trigram = trigram_probabilities[trigram]\n",
        "\n",
        "print(f\"probability for trigram {trigram} estimated as {probability_hat_trigram}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3hxlqyMhEla",
        "outputId": "1acb58d0-c223-4b31-ade6-8a03d89fca53"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "besides the trigram ('are', 'you', 'happy') we also use bigram ('you', 'happy') and unigram (happy)\n",
            "\n",
            "probability for trigram ('are', 'you', 'happy') not found\n",
            "probability for bigram ('you', 'happy') not found\n",
            "probability for unigram happy found\n",
            "\n",
            "probability for trigram ('are', 'you', 'happy') estimated as 0.06400000000000002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pre-calculated probabilities of all types of n-grams\n",
        "trigram_probabilities = {('i', 'am', 'happy'): 0.15}\n",
        "bigram_probabilities = {( 'am', 'happy'): 0.3}\n",
        "unigram_probabilities = {'happy': 0.4}\n",
        "\n",
        "# the weights come from optimization on a validation set\n",
        "lambda_1 = 0.8\n",
        "lambda_2 = 0.15\n",
        "lambda_3 = 0.05\n",
        "\n",
        "# this is the input trigram we need to estimate\n",
        "trigram = ('i', 'am', 'happy')\n",
        "\n",
        "# find the last bigram and unigram of the input\n",
        "bigram = trigram[1: 3]\n",
        "unigram = trigram[2]\n",
        "print(f\"besides the trigram {trigram} we also use bigram {bigram} and unigram ({unigram})\\n\")\n",
        "\n",
        "# in the production code, you would need to check if the probability n-gram dictionary contains the n-gram\n",
        "probability_hat_trigram = lambda_1 * trigram_probabilities[trigram] \n",
        "+ lambda_2 * bigram_probabilities[bigram]\n",
        "+ lambda_3 * unigram_probabilities[unigram]\n",
        "\n",
        "print(f\"estimated probability of the input trigram {trigram} is {probability_hat_trigram}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxU0GA_jha2P",
        "outputId": "66fdf949-38d1-42e4-9c38-37853647a22a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "besides the trigram ('i', 'am', 'happy') we also use bigram ('am', 'happy') and unigram (happy)\n",
            "\n",
            "estimated probability of the input trigram ('i', 'am', 'happy') is 0.12\n"
          ]
        }
      ]
    }
  ]
}