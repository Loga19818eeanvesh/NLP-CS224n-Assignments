{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_C2W4_L_CBOW-Model.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMNR31W4E45+1xfQyiPAFNI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Loga19818eeanvesh/Natural_Language_Processing-Assignments/blob/main/NLP_C2W4_L2_Word2Vec_CBOW_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEaOuDPBpS3R",
        "outputId": "0d916f96-137f-4cf1-acf8-5d35b843e28a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: emoji in /usr/local/lib/python3.7/dist-packages (1.6.3)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.7/dist-packages (1.6.3)\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "!pip install emoji\n",
        "\n",
        "import sys\n",
        "!{sys.executable} -m pip install emoji # to resolve: ModuleNotFoundError: No module named 'emoji'\n",
        "\n",
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "import emoji\n",
        "import numpy as np\n",
        "\n",
        "nltk.download('punkt')  # download pre-trained Punkt tokenizer for English"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the 'relu' function that will include the steps previously seen\n",
        "def relu(z):\n",
        "    result = z.copy()\n",
        "    result[result < 0] = 0\n",
        "    return result"
      ],
      "metadata": {
        "id": "MrCUPCXPzZnn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the 'softmax' function that will include the steps previously seen\n",
        "def softmax(z):\n",
        "    e_z = np.exp(z)\n",
        "    sum_e_z = np.sum(e_z)\n",
        "    return e_z / sum_e_z"
      ],
      "metadata": {
        "id": "e0BjdYkCzd6v"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dict(words):\n",
        "  words = list(set(words))\n",
        "  words.sort()\n",
        "  l = len(words)\n",
        "\n",
        "  ind = 0\n",
        "  word2ind = {}\n",
        "  ind2word = {}\n",
        "  for w in words:\n",
        "    word2ind[w] = ind\n",
        "    ind2word[ind] = w\n",
        "    ind += 1\n",
        "\n",
        "  return word2ind, ind2word\n",
        "\n",
        "# Define the 'tokenize' function that will include the steps previously seen\n",
        "def tokenize(corpus):\n",
        "    data = re.sub(r'[,!?;-]+', '.', corpus)\n",
        "    data = nltk.word_tokenize(data)  # tokenize string to words\n",
        "    data = [ ch.lower() for ch in data\n",
        "             if ch.isalpha()\n",
        "             or ch == '.'\n",
        "             or emoji.get_emoji_regexp().search(ch)\n",
        "           ]\n",
        "    return data\n",
        "    \n",
        "# Define the 'get_windows' function as seen in a previous notebook\n",
        "def get_windows(words, C):\n",
        "    i = C\n",
        "    while i < len(words) - C:\n",
        "        center_word = words[i]\n",
        "        context_words = words[(i - C):i] + words[(i+1):(i+C+1)]\n",
        "        yield context_words, center_word\n",
        "        i += 1\n",
        "\n",
        "# Define the 'word_to_one_hot_vector' function as seen in a previous notebook\n",
        "def word_to_one_hot_vector(word, word2Ind, V):\n",
        "    one_hot_vector = np.zeros(V)\n",
        "    one_hot_vector[word2Ind[word]] = 1\n",
        "    return one_hot_vector\n",
        "\n",
        "# Define the 'context_words_to_vector' function as seen in a previous notebook\n",
        "def context_words_to_vector(context_words, word2Ind, V):\n",
        "    context_words_vectors = [word_to_one_hot_vector(w, word2Ind, V) for w in context_words]\n",
        "    context_words_vectors = np.mean(context_words_vectors, axis=0)\n",
        "    return context_words_vectors\n",
        "\n",
        "# Define the generator function 'get_training_example' as seen in a previous notebook\n",
        "def get_training_example(words, C, word2Ind, V):\n",
        "    for context_words, center_word in get_windows(words, C):\n",
        "        yield context_words_to_vector(context_words, word2Ind, V), word_to_one_hot_vector(center_word, word2Ind, V)"
      ],
      "metadata": {
        "id": "1wVrY7PdzeDN"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = 'I am happy because I am learning'\n",
        "words = tokenize(corpus)\n",
        "word2Ind, Ind2word = get_dict(words)\n",
        "V = len(word2Ind)\n",
        "N=3"
      ],
      "metadata": {
        "id": "VOwiOWub50Ml"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(10)\n"
      ],
      "metadata": {
        "id": "uuC5pCLl6jt7"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.zeros((V,1))\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GCvHl5B6yiy",
        "outputId": "6fad6e74-a6dd-406e-d199-ba09c630afb5"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W1 = np.random.rand(N,V)\n",
        "print(W1)\n",
        "b1 = np.random.rand(N,1)\n",
        "print(b1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBVmZaax7OjY",
        "outputId": "d1fe26fc-3c05-46f7-e459-3e7d3cf9e946"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.30306256 0.24207588 0.55757819 0.56550702 0.47513225]\n",
            " [0.29279798 0.06425106 0.97881915 0.33970784 0.49504863]\n",
            " [0.97708073 0.44077382 0.31827281 0.51979699 0.57813643]]\n",
            "[[0.85393375]\n",
            " [0.06809727]\n",
            " [0.46453081]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W2 = np.random.rand(V,N)\n",
        "print(W2)\n",
        "b2 = np.random.rand(V,1)\n",
        "print(b2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wu5m9jPG7oox",
        "outputId": "64cf4834-813c-4e42-f3fb-6dfa7ba221d9"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.46978529 0.59825567 0.14762019]\n",
            " [0.18403482 0.64507213 0.04862801]\n",
            " [0.24861251 0.54240852 0.22677334]\n",
            " [0.38141153 0.92223279 0.92535687]\n",
            " [0.56674992 0.53347088 0.01486002]]\n",
            "[[0.97789926]\n",
            " [0.5730289 ]\n",
            " [0.791757  ]\n",
            " [0.56155736]\n",
            " [0.87733524]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BEGIN your code here\n",
        "print(f'V (vocabulary size): {V}')\n",
        "print(f'N (embedding size / size of the hidden layer): {N}')\n",
        "print(f'size of W1: {W1.shape} (NxV)')\n",
        "print(f'size of b1: {b1.shape} (Nx1)')\n",
        "print(f'size of W2: {W2.shape} (VxN)')\n",
        "print(f'size of b2: {b2.shape} (Vx1)')\n",
        "# END your code here"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1COSAhPq8c-6",
        "outputId": "3e6db875-93df-4e0d-b8bb-dadaa35a0512"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "V (vocabulary size): 5\n",
            "N (embedding size / size of the hidden layer): 3\n",
            "size of W1: (3, 5) (NxV)\n",
            "size of b1: (3, 1) (Nx1)\n",
            "size of W2: (5, 3) (VxN)\n",
            "size of b2: (5, 1) (Vx1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_examples = get_training_example(words, 2, word2Ind, V)"
      ],
      "metadata": {
        "id": "-QL4bELq83T2"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_array, y_array = next(training_examples)"
      ],
      "metadata": {
        "id": "EthcRqap83dP"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_array"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMISDbAY9FCK",
        "outputId": "55503703-12ec-48e4-bca6-23c76baedec2"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.25, 0.25, 0.  , 0.5 , 0.  ])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_array"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RsA90-sL9Gr2",
        "outputId": "15f9b509-7153-4080-c7b9-ee05f1acb062"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 1., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = x_array.copy()\n",
        "x.shape = (V, 1)\n",
        "print('x')\n",
        "print(x)\n",
        "print()\n",
        "\n",
        "y = y_array.copy()\n",
        "y.shape = (V, 1)\n",
        "print('y')\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isCMirNi9PSC",
        "outputId": "b695fca3-dd59-456c-fff9-ac736cc6dfd1"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x\n",
            "[[0.25]\n",
            " [0.25]\n",
            " [0.  ]\n",
            " [0.5 ]\n",
            " [0.  ]]\n",
            "\n",
            "y\n",
            "[[0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z1 = np.dot(W1, x) + b1\n",
        "z1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOKEz7tB9Tqz",
        "outputId": "128fadb4-36ac-4cea-cb0e-ec8fbed5e91e"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.27297187],\n",
              "       [0.32721345],\n",
              "       [1.07889294]])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h = relu(z1)\n",
        "h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHY4Xohp9bFl",
        "outputId": "1a4711e8-4563-42c9-ed0a-ebdea8309952"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.27297187],\n",
              "       [0.32721345],\n",
              "       [1.07889294]])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BEGIN your code here\n",
        "z2 = np.dot(W2, h) + b2\n",
        "# END your code here\n",
        "\n",
        "z2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrLNJ1tz9fbW",
        "outputId": "aaf36635-c210-497f-fb57-458141276db5"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.93094641],\n",
              "       [1.07084075],\n",
              "       [1.53038125],\n",
              "       [2.34721149],\n",
              "       [1.78938318]])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BEGIN your code here\n",
        "y_hat = softmax(z2)\n",
        "# END your code here\n",
        "\n",
        "y_hat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1-Wz5h_9iWD",
        "outputId": "1b0f0dd8-81ca-4434-b869-1c635fd570d5"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.22334656],\n",
              "       [0.09450181],\n",
              "       [0.14962909],\n",
              "       [0.33865766],\n",
              "       [0.19386488]])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_entropy_loss(y_predicted, y_actual):\n",
        "    # BEGIN your code here\n",
        "    loss = np.sum(-np.log(y_predicted)*y_actual)\n",
        "    # END your code here\n",
        "    return loss"
      ],
      "metadata": {
        "id": "46iUlYF39qgs"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cross_entropy_loss(y_hat, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xay6byIY992c",
        "outputId": "0a13f635-109b-4ada-daa2-8efb31f31a8a"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.899595784663097"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BEGIN your code here\n",
        "grad_b2 = y_hat - y\n",
        "# END your code here\n",
        "\n",
        "grad_b2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZL_05P2G-B8y",
        "outputId": "05d1dbf8-bf5b-42e8-acd2-2dba2ba08ac7"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.22334656],\n",
              "       [ 0.09450181],\n",
              "       [-0.85037091],\n",
              "       [ 0.33865766],\n",
              "       [ 0.19386488]])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BEGIN your code here\n",
        "grad_W2 = np.dot(y_hat - y, h.T)\n",
        "# END your code here\n",
        "\n",
        "grad_W2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mr1PlCOy-LGm",
        "outputId": "c9df25d2-d140-463d-bd7e-75d0489f0561"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.28431389,  0.073082  ,  0.24096703],\n",
              "       [ 0.12029815,  0.03092226,  0.10195734],\n",
              "       [-1.08249825, -0.2782528 , -0.91745917],\n",
              "       [ 0.43110167,  0.11081334,  0.36537535],\n",
              "       [ 0.24678454,  0.0634352 ,  0.20915945]])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BEGIN your code here\n",
        "grad_b1 = relu(np.dot(W2.T, y_hat - y))\n",
        "# END your code here\n",
        "\n",
        "grad_b1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xsTQlOkH-OiH",
        "outputId": "de8d6354-7913-4ce2-9970-5cb3c8a91d9c"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.14994455],\n",
              "       [0.14907287],\n",
              "       [0.16098447]])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BEGIN your code here\n",
        "grad_W1 = np.dot(relu(np.dot(W2.T, y_hat - y)), x.T)\n",
        "# END your code here\n",
        "\n",
        "grad_W1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSWCTRIK-Twm",
        "outputId": "b140c9c1-048c-4415-f003-7c42de072ab5"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.03748614, 0.03748614, 0.        , 0.07497228, 0.        ],\n",
              "       [0.03726822, 0.03726822, 0.        , 0.07453644, 0.        ],\n",
              "       [0.04024612, 0.04024612, 0.        , 0.08049223, 0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BEGIN your code here\n",
        "print(f'V (vocabulary size): {V}')\n",
        "print(f'N (embedding size / size of the hidden layer): {N}')\n",
        "print(f'size of grad_W1: {grad_W1.shape} (NxV)')\n",
        "print(f'size of grad_b1: {grad_b1.shape} (Nx1)')\n",
        "print(f'size of grad_W2: {grad_W2.shape} (VxN)')\n",
        "print(f'size of grad_b2: {grad_b2.shape} (Vx1)')\n",
        "# END your code here"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQm_3BA_-bFk",
        "outputId": "720a71df-3fa0-4dd8-9d54-0ee184f5ff94"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "V (vocabulary size): 5\n",
            "N (embedding size / size of the hidden layer): 3\n",
            "size of grad_W1: (3, 5) (NxV)\n",
            "size of grad_b1: (3, 1) (Nx1)\n",
            "size of grad_W2: (5, 3) (VxN)\n",
            "size of grad_b2: (5, 1) (Vx1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "alpha = 0.03\n",
        "\n",
        "W1_new = W1 - alpha * grad_W1\n",
        "W2_new = W2 - alpha * grad_W2\n",
        "b1_new = b1 - alpha * grad_b1\n",
        "b2_new = b2 - alpha * grad_b2"
      ],
      "metadata": {
        "id": "zTHgFDlf-frO"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAxEiQ2U-sew",
        "outputId": "016a1550-36db-4ea1-cd76-ea768f3d976f"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.30306256, 0.24207588, 0.55757819, 0.56550702, 0.47513225],\n",
              "       [0.29279798, 0.06425106, 0.97881915, 0.33970784, 0.49504863],\n",
              "       [0.97708073, 0.44077382, 0.31827281, 0.51979699, 0.57813643]])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loop through each word of the vocabulary\n",
        "for word in word2Ind:\n",
        "    # extract the column corresponding to the index of the word in the vocabulary\n",
        "    word_embedding_vector = W1[:, word2Ind[word]]\n",
        "    \n",
        "    print(f'{word}: {word_embedding_vector}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZXlgdvx-xJC",
        "outputId": "8237de7e-4c07-493b-b324-384664e727f6"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "am: [0.30306256 0.29279798 0.97708073]\n",
            "because: [0.24207588 0.06425106 0.44077382]\n",
            "happy: [0.55757819 0.97881915 0.31827281]\n",
            "i: [0.56550702 0.33970784 0.51979699]\n",
            "learning: [0.47513225 0.49504863 0.57813643]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W2.T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzXiuHKI-5L8",
        "outputId": "f26fccb5-132e-4911-b85b-c34ca363544c"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.46978529, 0.18403482, 0.24861251, 0.38141153, 0.56674992],\n",
              "       [0.59825567, 0.64507213, 0.54240852, 0.92223279, 0.53347088],\n",
              "       [0.14762019, 0.04862801, 0.22677334, 0.92535687, 0.01486002]])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loop through each word of the vocabulary\n",
        "for word in word2Ind:\n",
        "    # extract the column corresponding to the index of the word in the vocabulary\n",
        "    word_embedding_vector = W2.T[:, word2Ind[word]]\n",
        "    \n",
        "    print(f'{word}: {word_embedding_vector}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8KhvH0d-8EW",
        "outputId": "4cd5984f-8adf-4990-f689-826b9708daca"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "am: [0.46978529 0.59825567 0.14762019]\n",
            "because: [0.18403482 0.64507213 0.04862801]\n",
            "happy: [0.24861251 0.54240852 0.22677334]\n",
            "i: [0.38141153 0.92223279 0.92535687]\n",
            "learning: [0.56674992 0.53347088 0.01486002]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BEGIN your code here\n",
        "W3 = (W1+W2.T)/2\n",
        "# END your code here\n",
        "\n",
        "W3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLRWAnHz--QK",
        "outputId": "6be5910e-6965-4d98-d31f-2b0b6b8cefed"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.38642393, 0.21305535, 0.40309535, 0.47345928, 0.52094109],\n",
              "       [0.44552682, 0.35466159, 0.76061383, 0.63097032, 0.51425976],\n",
              "       [0.56235046, 0.24470092, 0.27252307, 0.72257693, 0.29649823]])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loop through each word of the vocabulary\n",
        "for word in word2Ind:\n",
        "    # extract the column corresponding to the index of the word in the vocabulary\n",
        "    word_embedding_vector = W3[:, word2Ind[word]]\n",
        "    \n",
        "    print(f'{word}: {word_embedding_vector}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVMOjKP9_AXX",
        "outputId": "39526031-536b-4f48-b2a8-c2cc86d0eb1f"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "am: [0.38642393 0.44552682 0.56235046]\n",
            "because: [0.21305535 0.35466159 0.24470092]\n",
            "happy: [0.40309535 0.76061383 0.27252307]\n",
            "i: [0.47345928 0.63097032 0.72257693]\n",
            "learning: [0.52094109 0.51425976 0.29649823]\n"
          ]
        }
      ]
    }
  ]
}